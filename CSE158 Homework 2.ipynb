{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from urllib.request import urlopen\n",
    "import scipy.optimize\n",
    "import random\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "\n",
    "def parseDataFromURL(fname):\n",
    "  for l in urlopen(fname):\n",
    "    yield eval(l)\n",
    "\n",
    "def parseData(fname):\n",
    "  for l in open(fname):\n",
    "    yield eval(l)\n",
    "\n",
    "print(\"Reading data...\")\n",
    "# Download from http://jmcauley.ucsd.edu/cse258/data/amazon/book_descriptions_50000.json\n",
    "data = list(parseData(\"data/amazon/book_descriptions_50000.json\"))\n",
    "print(\"done\")\n",
    "\n",
    "### Naive bayes to determine p(childrens book | mentions wizards and mentions witches) ###\n",
    "\n",
    "# p(childrens book)\n",
    "prior = [\"Children's Books\" in b['categories'] for b in data]\n",
    "prior = sum(prior) * 1.0 / len(prior)\n",
    "\n",
    "# p(isn't children's book)\n",
    "prior_neg = 1 - prior\n",
    "\n",
    "# p(mentions wizards | is childrens)\n",
    "p1 = ['wizard' in b['description'] for b in data if \"Children's Books\" in b['categories']]\n",
    "p1 = sum(p1) * 1.0 / len(p1)\n",
    "\n",
    "# p(mentions wizards | isn't childrens)\n",
    "p1_neg = ['wizard' in b['description'] for b in data if not (\"Children's Books\" in b['categories'])]\n",
    "p1_neg = sum(p1_neg) * 1.0 / len(p1_neg)\n",
    "\n",
    "# p(mentions witches | is childrens)\n",
    "p2 = ['witch' in b['description'] for b in data if \"Children's Books\" in b['categories']]\n",
    "p2 = sum(p2) * 1.0 / len(p2)\n",
    "\n",
    "# p(mentions witches | isn't childrens)\n",
    "p2_neg = ['witch' in b['description'] for b in data if not (\"Children's Books\" in b['categories'])]\n",
    "p2_neg = sum(p2_neg) * 1.0 / len(p2_neg)\n",
    "\n",
    "# Prediction\n",
    "\n",
    "score = prior * p1 * p2\n",
    "score_neg = prior_neg * p1_neg * p2_neg\n",
    "\n",
    "# Actual ('non-naive') probability\n",
    "\n",
    "p = [\"Children's Books\" in b['categories'] for b in data if 'witch' in b['description'] and 'wizard' in b['description']]\n",
    "p = sum(p) * 1.0 / len(p)\n",
    "\n",
    "### Logistic Regression -- \"Judging a book by its cover\"\n",
    "\n",
    "print(\"Reading data...\")\n",
    "# Download from http://jmcauley.ucsd.edu/cse255/data/amazon/book_images_5000.json\n",
    "data = list(parseData(\"data/amazon/book_images_5000.json\"))\n",
    "print(\"done\")\n",
    "\n",
    "X = [b['image_feature'] for b in data]\n",
    "y = [\"Children's Books\" in b['categories'] for b in data]\n",
    "\n",
    "X_train = X[:2500]\n",
    "y_train = y[:2500]\n",
    "\n",
    "X_test = X[2500:]\n",
    "y_test = y[2500:]\n",
    "\n",
    "# Create a support vector classifier object, with regularization parameter C = 1000\n",
    "# clf = svm.SVC(C=1000, kernel='linear')\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# train_predictions = clf.predict(X_train)\n",
    "# test_predictions = clf.predict(X_test)\n",
    "\n",
    "# Logistic regression classifier\n",
    "mod = linear_model.LogisticRegression(C=1.0)\n",
    "mod.fit(X_train, y_train)\n",
    "\n",
    "train_predictions = mod.predict(X_train)\n",
    "test_predictions = mod.predict(X_test)\n",
    "\n",
    "\n",
    "### Diagnostics\n",
    "\n",
    "# From https://archive.ics.uci.edu/ml/datasets/Polish+companies+bankruptcy+data\n",
    "f = open(\"5year.arff\", 'r')\n",
    "\n",
    "# Reading in data\n",
    "while not '@data' in f.readline():\n",
    "    pass\n",
    "\n",
    "dataset = []\n",
    "for l in f:\n",
    "    if '?' in l: # Missing entry\n",
    "        continue\n",
    "    l = l.split(',')\n",
    "    values = [1] + [float(x) for x in l]\n",
    "    values[-1] = values[-1] > 0 # Convert to bool\n",
    "    dataset.append(values)\n",
    "\n",
    "# Data setup\n",
    "X = [d[:-1] for d in dataset]\n",
    "y = [d[-1] for d in dataset]\n",
    "\n",
    "# Fit model\n",
    "mod = linear_model.LogisticRegression(C=1.0)\n",
    "mod.fit(X,y)\n",
    "\n",
    "pred = mod.predict(X)\n",
    "\n",
    "# How many positive predictions?\n",
    "sum(pred)\n",
    "\n",
    "# Balanced model\n",
    "mod = linear_model.LogisticRegression(C=1.0, class_weight='balanced')\n",
    "mod.fit(X,y)\n",
    "\n",
    "pred = mod.predict(X)\n",
    "\n",
    "# How many positive predictions?\n",
    "sum(pred)\n",
    "\n",
    "# Train/validation/test splits\n",
    "\n",
    "# Shuffle the data\n",
    "Xy = list(zip(X,y))\n",
    "random.shuffle(Xy)\n",
    "\n",
    "X = [d[0] for d in Xy]\n",
    "y = [d[1] for d in Xy]\n",
    "\n",
    "N = len(y)\n",
    "\n",
    "Ntrain = 1000\n",
    "Nvalid = 1000\n",
    "Ntest = 1031\n",
    "\n",
    "Xtrain = X[:Ntrain]\n",
    "Xvalid = X[Ntrain:Ntrain+Nvalid]\n",
    "Xtest = X[Ntrain+Nvalid:]\n",
    "\n",
    "ytrain = y[:Ntrain]\n",
    "yvalid = y[Ntrain:Ntrain+Nvalid]\n",
    "ytest = y[Ntrain+Nvalid:]\n",
    "\n",
    "mod.fit(Xtrain, ytrain)\n",
    "\n",
    "pred = mod.predict(Xtest)\n",
    "\n",
    "correct = pred == ytest\n",
    "\n",
    "# True positives, false positives, etc.\n",
    "\n",
    "TP_ = numpy.logical_and(pred, ytest)\n",
    "FP_ = numpy.logical_and(pred, numpy.logical_not(ytest))\n",
    "TN_ = numpy.logical_and(numpy.logical_not(pred), numpy.logical_not(ytest))\n",
    "FN_ = numpy.logical_and(numpy.logical_not(pred), ytest)\n",
    "\n",
    "TP = sum(TP_)\n",
    "FP = sum(FP_)\n",
    "TN = sum(TN_)\n",
    "FN = sum(FN_)\n",
    "\n",
    "# accuracy\n",
    "sum(correct) / len(correct)\n",
    "(TP + TN) / (TP + FP + TN + FN)\n",
    "\n",
    "# BER\n",
    "1 - 0.5 * (TP / (TP + FN) + TN / (TN + FP))\n",
    "\n",
    "# Ranking\n",
    "\n",
    "scores = mod.decision_function(Xtest)\n",
    "\n",
    "scores_labels = list(zip(scores, ytest))\n",
    "scores_labels.sort(reverse = True)\n",
    "\n",
    "sortedlabels = [x[1] for x in scores_labels]\n",
    "\n",
    "# precision / recall\n",
    "retrieved = sum(pred)\n",
    "relevant = sum(ytest)\n",
    "intersection = sum([y and p for y,p in zip(ytest,pred)])\n",
    "\n",
    "precision = intersection / retrieved\n",
    "recall = intersection / relevant\n",
    "\n",
    "# precision at 10\n",
    "sum(sortedlabels[:10]) / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from urllib.request import urlopen\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseData(fname):\n",
    "  for l in open(fname):\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "# Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_beer = list(parseData(\"beer_50000.json\"))\n",
    "cat = [d['beer/style'] for d in parsed_beer]\n",
    "abv = [d['beer/ABV'] for d in parsed_beer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryCounts = {}\n",
    "for d in parsed_beer:\n",
    "    if d['beer/style'] not in categoryCounts.keys():\n",
    "        categoryCounts[d['beer/style']] = 0\n",
    "    categoryCounts[d['beer/style']] += 1\n",
    "categories = [c for c in categoryCounts if categoryCounts[c] > 1000]\n",
    "catID = dict(zip(list(categories),range(len(categories))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(cat, abv, test_size=0.5)\n",
    "train_matrix = np.zeros((25000,13))\n",
    "test_matrix = np.zeros((25000,13))\n",
    "train_binary = [1 if x > 7 else 0 for x in y_train]\n",
    "test_binary = [1 if x > 7 else 0 for x in y_test]\n",
    "for x in range(len(x_train)):\n",
    "    if x_train[x] in catID.keys():\n",
    "        train_matrix[x][catID[x_train[x]]] = 1\n",
    "    if x_test[x] in catID.keys():\n",
    "        test_matrix[x][catID[x_test[x]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=10,class_weight='balanced',solver='liblinear').fit(train_matrix, train_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'True Positive': 0.6852984239083627,\n",
       " 'False Positive': 0.01112853835237882,\n",
       " 'True Negative': 0.9888714616476212,\n",
       " 'False Negative': 0.31470157609163724,\n",
       " 'BER': 0.16291505722200805,\n",
       " 'Accuracy': 0.84788}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finds the True Positive, False Positive, True Negative, and False Negative array values\n",
    "TP_ = np.logical_and(pred, test_binary)\n",
    "FP_ = np.logical_and(pred, np.logical_not(test_binary))\n",
    "TN_ = np.logical_and(np.logical_not(pred), np.logical_not(test_binary))\n",
    "FN_ = np.logical_and(np.logical_not(pred), test_binary)\n",
    "\n",
    "#Finds the number of True Positive, False Positive, True Negative, and False Negative\n",
    "TP = sum(TP_)\n",
    "FP = sum(FP_)\n",
    "TN = sum(TN_)\n",
    "FN = sum(FN_)\n",
    "\n",
    "#Converts To Rates\n",
    "TPR = TP/(TP+FN)\n",
    "FPR = FP/(FP+TN)\n",
    "TNR = TN/(TN+FP)\n",
    "FNR = FN/(FN+TP)\n",
    "\n",
    "# accuracy\n",
    "#sum(correct) / len(correct)\n",
    "accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
    "\n",
    "#Calculates Balanced Error Rate\n",
    "ber = 1 - 0.5 * (TP / (TP + FN) + TN / (TN + FP))\n",
    "{'BER':ber, 'Accuracy':accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "# Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aro = [d['review/aroma'] for d in parsed_beer]\n",
    "appear = [d['review/appearance'] for d in parsed_beer]\n",
    "pal = [d['review/palate'] for d in parsed_beer]\n",
    "tas = [d['review/taste'] for d in parsed_beer]\n",
    "over = [d['review/overall'] for d in parsed_beer]\n",
    "review_len = [len(d['review/text']) for d in parsed_beer]\n",
    "stan = [x/max(review_len) for x in review_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2,x_test2,y_train2,y_test2=train_test_split(np.array([cat,aro,appear,pal,tas,over,stan]).T,abv,test_size=0.5)\n",
    "train_matrix2 = np.zeros((25000,19))\n",
    "test_matrix2 = np.zeros((25000,19))\n",
    "train_binary2 = [1 if x > 7 else 0 for x in y_train2]\n",
    "test_binary2 = [1 if x > 7 else 0 for x in y_test2]\n",
    "for x in range(len(x_train2)):\n",
    "    if x_train2[x][0] in catID.keys():\n",
    "        train_matrix2[x][catID[x_train2[x][0]]] = 1\n",
    "    if x_test2[x][0] in catID.keys():\n",
    "        test_matrix2[x][catID[x_test2[x][0]]] = 1\n",
    "    \n",
    "    train_matrix2[x][13] = x_train2[x][1]\n",
    "    train_matrix2[x][14] = x_train2[x][2]\n",
    "    train_matrix2[x][15] = x_train2[x][3]\n",
    "    train_matrix2[x][16] = x_train2[x][4]\n",
    "    train_matrix2[x][17] = x_train2[x][5]\n",
    "    train_matrix2[x][18] = x_train2[x][6]\n",
    "    \n",
    "    test_matrix2[x][13] = x_test2[x][1]\n",
    "    test_matrix2[x][14] = x_test2[x][2]\n",
    "    test_matrix2[x][15] = x_test2[x][3]\n",
    "    test_matrix2[x][16] = x_test2[x][4]\n",
    "    test_matrix2[x][17] = x_test2[x][5]\n",
    "    test_matrix2[x][18] = x_test2[x][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = LogisticRegression(C=10,class_weight='balanced',solver='liblinear').fit(train_matrix2, train_binary2)\n",
    "pred2 = clf2.predict(test_matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'True Positive': 0.7775187775187775,\n",
       " 'False Positive': 0.06819706342699561,\n",
       " 'True Negative': 0.9318029365730044,\n",
       " 'False Negative': 0.22248122248122248,\n",
       " 'BER': 0.1453391429541091,\n",
       " 'Accuracy': 0.86032}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finds the True Positive, False Positive, True Negative, and False Negative array values\n",
    "TP_2 = np.logical_and(pred2, test_binary2)\n",
    "FP_2 = np.logical_and(pred2, np.logical_not(test_binary2))\n",
    "TN_2 = np.logical_and(np.logical_not(pred2), np.logical_not(test_binary2))\n",
    "FN_2 = np.logical_and(np.logical_not(pred2), test_binary2)\n",
    "\n",
    "#Finds the number of True Positive, False Positive, True Negative, and False Negative\n",
    "TP2 = sum(TP_2)\n",
    "FP2 = sum(FP_2)\n",
    "TN2 = sum(TN_2)\n",
    "FN2 = sum(FN_2)\n",
    "\n",
    "#Converts To Rates\n",
    "TPR2 = TP2/(TP2+FN2)\n",
    "FPR2 = FP2/(FP2+TN2)\n",
    "TNR2 = TN2/(TN2+FP2)\n",
    "FNR2 = FN2/(FN2+TP2)\n",
    "\n",
    "# accuracy\n",
    "#sum(correct) / len(correct)\n",
    "accuracy2 = (TP2 + TN2) / (TP2 + FP2 + TN2 + FN2)\n",
    "\n",
    "#Calculates Balanced Error Rate\n",
    "ber2 = 1 - 0.5 * (TP2 / (TP2 + FN2) + TN2 / (TN2 + FP2))\n",
    "{'BER':ber2, 'Accuracy':accuracy2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "# Create 4 logistic regression models or retrain 1 4 times with different C values\n",
    "# Keep splits from problem 2 but split the test set further in half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x,test_x,val_y,test_y=train_test_split(test_matrix2,test_binary2,test_size=0.5)\n",
    "\n",
    "c_values = [0.000001, 0.00001, 0.0001, 0.001]\n",
    "models = [[train_matrix2,train_binary2],[val_x,val_y],[test_x,test_y]]\n",
    "berDict = {0.000001:[], 0.00001:[], 0.0001:[], 0.001:[]}\n",
    "for x in c_values:\n",
    "    for y in range(3):\n",
    "        lr = LogisticRegression(C=x,class_weight='balanced',solver='liblinear').fit(train_matrix2, train_binary2)\n",
    "        predC = lr.predict(models[y][0])\n",
    "\n",
    "        #Finds the True Positive, False Positive, True Negative, and False Negative array values\n",
    "        TP_C = np.logical_and(predC, models[y][1])\n",
    "        FP_C = np.logical_and(predC, np.logical_not(models[y][1]))\n",
    "        TN_C = np.logical_and(np.logical_not(predC), np.logical_not(models[y][1]))\n",
    "        FN_C = np.logical_and(np.logical_not(predC), models[y][1])\n",
    "\n",
    "        #Finds the number of True Positive, False Positive, True Negative, and False Negative\n",
    "        TPC = sum(TP_C)\n",
    "        FPC = sum(FP_C)\n",
    "        TNC = sum(TN_C)\n",
    "        FNC = sum(FN_C)\n",
    "\n",
    "        #Converts To Rates\n",
    "        TPRC = TPC/(TPC+FNC)\n",
    "        FPRC = FPC/(FPC+TNC)\n",
    "        TNRC = TNC/(TNC+FPC)\n",
    "        FNRC = FNC/(FNC+TPC)\n",
    "\n",
    "        #Calculates Balanced Error Rate\n",
    "        berC = 1 - 0.5 * (TPC / (TPC + FNC) + TNC / (TNC + FPC))\n",
    "        berDict[x].append(berC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1e-06: [0.5, 0.5, 0.5],\n",
       " 1e-05: [0.5, 0.5, 0.5],\n",
       " 0.0001: [0.38815437028201183, 0.3845060879628125, 0.39007704252338526],\n",
       " 0.001: [0.1594659741307387, 0.1580697293043255, 0.15940326752556233]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTMOR = pd.DataFrame(train_matrix2).drop(columns=[18])\n",
    "dfVXOR = pd.DataFrame(val_x).drop(columns=[18])\n",
    "dfTXOR = pd.DataFrame(test_x).drop(columns=[18])\n",
    "\n",
    "dfTMOS = pd.DataFrame(train_matrix2).drop(columns=[13,14,15,16,17])\n",
    "dfVXOS = pd.DataFrame(val_x).drop(columns=[13,14,15,16,17])\n",
    "dfTXOS = pd.DataFrame(test_x).drop(columns=[13,14,15,16,17])\n",
    "\n",
    "dfTMRS = pd.DataFrame(train_matrix2).drop(columns=[0,1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "dfVXRS = pd.DataFrame(val_x).drop(columns=[0,1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "dfTXRS = pd.DataFrame(test_x).drop(columns=[0,1,2,3,4,5,6,7,8,9,10,11,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelOR = [[dfTMOR,train_binary2],[dfVXOR,val_y],[dfTXOR,test_y]]\n",
    "berDictOR = {0.000001:[], 0.00001:[], 0.0001:[], 0.001:[]}\n",
    "for x in c_values:\n",
    "    for y in range(3):\n",
    "        warnings.filterwarnings(action='ignore')\n",
    "        lrOR = LogisticRegression(C=x,class_weight='balanced',solver='liblinear').fit(dfTMOR, train_binary2)\n",
    "        predOR = lrOR.predict(modelOR[y][0])\n",
    "\n",
    "        #Finds the True Positive, False Positive, True Negative, and False Negative array values\n",
    "        TP_OR = np.logical_and(predOR, modelOR[y][1])\n",
    "        FP_OR = np.logical_and(predOR, np.logical_not(modelOR[y][1]))\n",
    "        TN_OR = np.logical_and(np.logical_not(predOR), np.logical_not(modelOR[y][1]))\n",
    "        FN_OR = np.logical_and(np.logical_not(predOR), modelOR[y][1])\n",
    "\n",
    "        #Finds the number of True Positive, False Positive, True Negative, and False Negative\n",
    "        TPOR = sum(TP_OR)\n",
    "        FPOR = sum(FP_OR)\n",
    "        TNOR = sum(TN_OR)\n",
    "        FNOR = sum(FN_OR)\n",
    "\n",
    "        #Converts To Rates\n",
    "        TPROR = TPOR/(TPOR+FNOR)\n",
    "        FPROR = FPOR/(FPOR+TNOR)\n",
    "        TNROR = TNOR/(TNOR+FPOR)\n",
    "        FNROR = FNOR/(FNOR+TPOR)\n",
    "\n",
    "        #Calculates Balanced Error Rate\n",
    "        berOR = 1 - 0.5 * (TPOR / (TPOR + FNOR) + TNOR / (TNOR + FPOR))\n",
    "        berDictOR[x].append(berOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelOS = [[dfTMOS,train_binary2],[dfVXOS,val_y],[dfTXOS,test_y]]\n",
    "berDictOS = {0.000001:[], 0.00001:[], 0.0001:[], 0.001:[]}\n",
    "for x in c_values:\n",
    "    for y in range(3):\n",
    "        warnings.filterwarnings(action='ignore')\n",
    "        lrOS = LogisticRegression(C=x,class_weight='balanced',solver='liblinear').fit(dfTMOS, train_binary2)\n",
    "        predOS = lrOS.predict(modelOS[y][0])\n",
    "\n",
    "        #Finds the True Positive, False Positive, True Negative, and False Negative array values\n",
    "        TP_OS = np.logical_and(predOS, modelOS[y][1])\n",
    "        FP_OS = np.logical_and(predOS, np.logical_not(modelOS[y][1]))\n",
    "        TN_OS = np.logical_and(np.logical_not(predOS), np.logical_not(modelOS[y][1]))\n",
    "        FN_OS = np.logical_and(np.logical_not(predOS), modelOS[y][1])\n",
    "\n",
    "        #Finds the number of True Positive, False Positive, True Negative, and False Negative\n",
    "        TPOS = sum(TP_OS)\n",
    "        FPOS = sum(FP_OS)\n",
    "        TNOS = sum(TN_OS)\n",
    "        FNOS = sum(FN_OS)\n",
    "\n",
    "        #Converts To Rates\n",
    "        TPROS = TPOS/(TPOS+FNOS)\n",
    "        FPROS = FPOS/(FPOS+TNOS)\n",
    "        TNROS = TNOS/(TNOS+FPOS)\n",
    "        FNROS = FNOS/(FNOS+TPOS)\n",
    "\n",
    "        #Calculates Balanced Error Rate\n",
    "        berOS = 1 - 0.5 * (TPOS / (TPOS + FNOS) + TNOS / (TNOS + FPOS))\n",
    "        berDictOS[x].append(berOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRS = [[dfTMRS,train_binary2],[dfVXRS,val_y],[dfTXRS,test_y]]\n",
    "berDictRS = {0.000001:[], 0.00001:[], 0.0001:[], 0.001:[]}\n",
    "for x in c_values:\n",
    "    for y in range(3):\n",
    "        warnings.filterwarnings(action='ignore')\n",
    "        lrRS = LogisticRegression(C=x,class_weight='balanced',solver='liblinear').fit(dfTMRS, train_binary2)\n",
    "        predRS = lrRS.predict(modelRS[y][0])\n",
    "\n",
    "        #Finds the True Positive, False Positive, True Negative, and False Negative array values\n",
    "        TP_RS = np.logical_and(predRS, modelRS[y][1])\n",
    "        FP_RS = np.logical_and(predRS, np.logical_not(modelRS[y][1]))\n",
    "        TN_RS = np.logical_and(np.logical_not(predRS), np.logical_not(modelRS[y][1]))\n",
    "        FN_RS = np.logical_and(np.logical_not(predRS), modelRS[y][1])\n",
    "\n",
    "        #Finds the number of True Positive, False Positive, True Negative, and False Negative\n",
    "        TPRS = sum(TP_RS)\n",
    "        FPRS = sum(FP_RS)\n",
    "        TNRS = sum(TN_RS)\n",
    "        FNRS = sum(FN_RS)\n",
    "\n",
    "        #Converts To Rates\n",
    "        TPRRS = TPRS/(TPRS+FNRS)\n",
    "        FPRRS = FPRS/(FPRS+TNRS)\n",
    "        TNRRS = TNRS/(TNRS+FPRS)\n",
    "        FNRRS = FNRS/(FNRS+TPRS)\n",
    "\n",
    "        #Calculates Balanced Error Rate\n",
    "        berRS = 1 - 0.5 * (TPRS / (TPRS + FNRS) + TNRS / (TNRS + FPRS))\n",
    "        berDictRS[x].append(berRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BER of Train,Val,Test One-Hot and Rating': {1e-06: [0.5, 0.5, 0.5],\n",
       "  1e-05: [0.5, 0.5, 0.5],\n",
       "  0.0001: [0.3914817759883479, 0.3893438104208299, 0.39663528342028376],\n",
       "  0.001: [0.1594537922683842, 0.16033979946345556, 0.1582714751911315]},\n",
       " 'BER of Train,Val,Test One-Hot and Review Length': {1e-06: [0.5, 0.5, 0.5],\n",
       "  1e-05: [0.5, 0.5, 0.5],\n",
       "  0.0001: [0.3914817759883479, 0.3893438104208299, 0.39663528342028376],\n",
       "  0.001: [0.1594537922683842, 0.16033979946345556, 0.1582714751911315]},\n",
       " 'BER of Train,Val,Test Rating and Review Length': {1e-06: [0.5, 0.5, 0.5],\n",
       "  1e-05: [0.5, 0.5, 0.5],\n",
       "  0.0001: [0.4758307258647011, 0.473684404231122, 0.4771078436765178],\n",
       "  0.001: [0.361846582795153, 0.3629030298731444, 0.35790860276354475]}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'BER of Train,Val,Test One-Hot and Rating': berDictOR,'BER of Train,Val,Test One-Hot and Review Length': berDictOR,\\\n",
    " 'BER of Train,Val,Test Rating and Review Length': berDictRS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6\n",
    "# Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = set()\n",
    "nodes = set()\n",
    "with open(\"egonet.txt\") as f:\n",
    "    for line in f.readlines():\n",
    "        coord_x, coord_y = line.rstrip(\"\\n\").split(\" \")\n",
    "        coord_x,coord_y = int(coord_x),int(coord_y)\n",
    "        edges.add((coord_x,coord_y))\n",
    "        edges.add((coord_y,coord_x))\n",
    "        nodes.add(coord_x)\n",
    "        nodes.add(coord_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afong\\Anaconda3\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py:579: MatplotlibDeprecationWarning: \n",
      "The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead.\n",
      "  if not cb.iterable(width):\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "for e in edges:\n",
    "  G.add_edge(e[0],e[1])\n",
    "nx.draw(G)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(nx.connected_components(G))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Connected Components': 3, 'Nodes In Largest Connected Component': 40}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'Connected Components': 3, 'Nodes In Largest Connected Component': len(list(nx.connected_components(G))[0])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest = sorted(list(list(nx.connected_components(G))[0]))\n",
    "lowID = largest[:len(largest)//2]\n",
    "highID = largest[len(largest)//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4224058769513316"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.normalized_cut_size(G,lowID,highID)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_cut(G,S,T,weight=None):\n",
    "    e = nx.edge_boundary(G,S,T,data=weight,default=1)\n",
    "    nce = sum(weight for u,v,weight in e)\n",
    "    vs = sum(d for v,d in G.degree(S,weight=weight))\n",
    "    vt = sum(d for v,d in G.degree(T, weight=weight))\n",
    "    return (1/2)*nce*((1/vs)+(1/vt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-774eceb61ca5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mhighTemp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlowTemp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m#curr_cost = nx.normalized_cut_size(G,lowTemp,highTemp)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mcurr_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalized_cut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlowTemp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhighTemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcurr_cost\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mcut_cost\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mcut_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurr_cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-40aff71f9846>\u001b[0m in \u001b[0;36mnormalized_cut\u001b[1;34m(G, S, T, weight)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mvt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnce\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mvs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mvt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "first_loop = False\n",
    "second_loop = False\n",
    "cut_cost = 0\n",
    "curr_cost = 1\n",
    "num = 0\n",
    "low = lowID\n",
    "high = highID\n",
    "while cut_cost < curr_cost:\n",
    "    change = False\n",
    "    print(1)\n",
    "    for x in low:\n",
    "        lowTemp = low\n",
    "        highTemp = high\n",
    "        highTemp.append(lowTemp.remove(x))\n",
    "        #curr_cost = nx.normalized_cut_size(G,lowTemp,highTemp)\n",
    "        curr_cost = normalized_cut(G,lowTemp,highTemp)\n",
    "        if curr_cost < cut_cost:\n",
    "            cut_cost = curr_cost\n",
    "            num = x\n",
    "            first_loop = True\n",
    "            second_loop = False\n",
    "            change = True\n",
    "    for x in high:\n",
    "        lowTemp = low\n",
    "        highTemp = high\n",
    "        lowTemp.append(highTemp.remove(x))\n",
    "        #curr_cost = nx.normalized_cut_size(G,lowTemp,highTemp)\n",
    "        curr_cost = normalized_cut(G,lowTemp,highTemp)\n",
    "        if curr_cost < cut_cost:\n",
    "            cut_cost = curr_cost\n",
    "            num = x\n",
    "            first_loop = False\n",
    "            second_loop = True\n",
    "            change = True\n",
    "    if change == True:\n",
    "        if first_loop == True:\n",
    "            high.append(low.remove(num))\n",
    "        else:\n",
    "            low.append(high.remove(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find all 3 and 4-cliques in the graph ###\n",
    "cliques3 = set()\n",
    "cliques4 = set()\n",
    "for n1 in nodes:\n",
    "  for n2 in nodes:\n",
    "    if not ((n1,n2) in edges): continue\n",
    "    for n3 in nodes:\n",
    "      if not ((n1,n3) in edges): continue\n",
    "      if not ((n2,n3) in edges): continue\n",
    "      clique = [n1,n2,n3]\n",
    "      clique.sort()\n",
    "      cliques3.add(tuple(clique))\n",
    "      for n4 in nodes:\n",
    "        if not ((n1,n4) in edges): continue\n",
    "        if not ((n2,n4) in edges): continue\n",
    "        if not ((n3,n4) in edges): continue\n",
    "        clique = [n1,n2,n3,n4]\n",
    "        clique.sort()\n",
    "        cliques4.add(tuple(clique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
